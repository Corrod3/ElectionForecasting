<!-- Methodology -->



<!-- Notizen from data work

There was no Exit Poll data across the cluster specifically for AfD, therefore I took the share of the total AfD result from the Others total result. This share is thus equal across age groups and gender

Shall we use the average of December and March wave. Or focus entirely on March wave?
-->

We want to employ two approaches to generate election forecasts from our data. In the first approach, the survey data is adjusted in a two step procedure: First, the representativeness of survey data to the general population is increased by finding appropiate weights. Then, a likely voter model is used to obtain an election forecast. Our second approach does this in one step: The survey data will be directly adjusted to the likely voter population based on exit poll data from the German federal election in 2013. 

## Post-stratifiation

In order to follow both procedures, we need methods to compute weights for different strata of the survey sample aiming at increased representativeness. 

A classical way to get these weights is *raking*. With raking weights are assigned to each respondent in order to match the marginal distribution of characteristics in the 'true' population. For example, if we know the distribution of education level and employment status in the population we can compute a weight for each so that the weighted survey sample has the same distribution of the characteristics as the 'true' population. 

Basically, raking estimates a joint distributions for each combination of characteristics. 

In formal terms, we can describe each combination of an individual and a characteristic with $x_{i,j} \in \{0,1\}$ where $i$ stands for the individual and $j$ for the characteristic. To illustrate, in the case of the characteristic gender ($j$): If $x_{i,j} = 1$ the individual $i$ is female and if $x_{i,j} = 0$ the individual $i$ is not female. Hence, each characteristic is modeled with a binary variable. $c_j$ expresses the prevalence of a characteristic in the population and raking estimates the weights $w_i$ such that:

\begin{equation}
c_j = \frac{\sum_{i = 1}^{n}w_i x_{i,j}}{\sum_{i = 1}^{n}w_i} \forall j
\end{equation}

The weights can then be used to compute the raking estimates for each observation in the survey $y$:

\begin{equation}
\hat y^{rake} = \frac{\sum_{i = 1}^{n}w_i y_{i}}{\sum_{i = 1}^{n}w_i} 
\end{equation}

<!-- @Goel.2017 use the anesrake package to execute this, alternatively survey  -->

However, raking is not ideal. It is often used if only marginal probabilities are available. This is also the case for some of our data. However, if the joint distribution of characteristics is known we can use *post-stratification* instead. In contrast to raking, post-stratification takes the distribution of combinations of characteristics in the population into account. In other words: It sub-divides the population into groups according to their characteristics. Formally, the post-stratification estimator can be expressed as follows [@Goel.2017, @Lohr.2010[p. 142f.]]:

\begin{equation}
 \hat y^{post} = \frac{\sum^{J}_{j=1}N_J \hat y_j}{\sum^{J}_{j=1}N_J} \text{ where } \hat y_j = \frac{1}{n_J} \sum_{i = 1}^{n_J} y_i  ,
\end{equation}

where $\hat y^{post}$ is the estimator of $y$ in the strata $j$, $N_J$ the size of the j-th strata in the population and $n_J$ the size of the j-th strata in the sample. From the equation it is obvious that post-stratification is only feasible if we have at least one observation for each strata ($n_J > 0$). But even for small strata sizes in the sample ($n_J < 30$) the standard errors will be large. This is a serious issue as the number of strata grows rapidly with each characteristic included. If we use for instance two gender categories and four age groups we have eight strata, if we add past vote (7 categories) we already have 54. As a result, we might only have a few individuals for each strata or even none. This has severe consequences: For example, estimating the population frequency of the strata female, old (60+) and FDP voter in 2013 with only few respondents in the sample will come with a large error.

Furthermore, our effort to post-stratification comes with another problem: Publically available data often only includes the distribution of pairs of characteristics or, in rare cases, triples (e.g. age, gender and past vote). Yet, the ideal would be to have the frequencies of strata of all variables that is correlated to the voting behaviour of a person. These would be certainly gender and age but also employment status, income, education and religion.^[Formally speaking, we need to know the number of individuals in each strata $N_j$] Knowing this distribution would enable us to fine tune our forecast. However, as they are not available we will mainly concentrate on combination of characteristics where we have the joint distribtuions. These are in particular age, gender and past votes (from exit polls) as well as combinations of age, gender, education, religion and/or employment from the census. 

The prior mentioned problem of empthy strata can be address in two ways: By aggregating the data to fill strata, which is sometimes criticised as ad-hoc, or with *model-based post-stratification*. In the model-based post-stratification approach the estimates for each strata are not based on the average in the strata as in the equation above, but the result of a multinomial logistic regression. In order to arrive at this regression results, demographic variables in the sample can be used. If we decide to implement this, we will orient ourself at the work of @Goel.2017.^[They are developing an r package for this (postr) and might be willing to share their r script (as they already anounced to make it public).] However, the implementation ultimately depends on the availability of the strata sizes in the true population. This is the major problem for our (second) application, as the exit polls do not publish the extensive contingency tables which reveal sub-group sizes in their voter sample.

## Likely voter models

**Moritz**

By the time we post-stratified and weighted our sample to resemble the population (first approach), we have not yet accounted for the problem of likely voter bias. Surveys tend to either include voters who say they will vote but eventually do not do so, or include voters who say they will not vote but finally cast a ballot [@Bernstein.2001]. Since this behaviour of individuals has turned out to be correlated across party preferences it is likely to bias our forecast [@Keeter.2016] 

Two families of methods are proposed by @Keeter.2016 to account for likely voter bias - *deterministic* and *propabilistic* methods. The former was initially proposed in @Perry.1960 and @Perry.1979 and tries to identify criteria that describe a voter as a likely voter on a scale from 0-7. Using a distinct set of questions such as "How likely are you to vote at the next national election?" respondents are assigned points on the likely voter scale and are eventually ranked. Using an estimate of the upcoming election turnout, a cut-of criteria determines which rank on the likely voter scale is needed to be included in the sample measuring the actual voting population.

The downside of such methods is that people below the threshold value of the scale have no affect at all on the actual forecast. This is addressed by probabilistic methods. Such an approach estimates on the basis of a set of predictor variables like demographic characteristics, partisanship or ideology a probability of a person to cast a ballot. By using this probability even people with a very low likelihood of voting affect the actual estimate to a certain degree. The downside of such methods is that it requires data on turnout and the predictor variables of the past election. Moreover, such models assume that turnout is time-stable for the population groups across past and future elections.[@Keeter.2016]

Applying such methods on our data, we are basically capable of using deterministic as well as probabilistic identification of likely voters. However, it is easier to use deterministic criteria since they do not require data on voting behaviour in the past election. <!-- with regard to estimate individual voting behaviour. --> On the downside, we would need an estimate for the turnout in the federal election. With probabilistic models we are not capable of estimating the probability for the sub-groups using for instance logistic regression since we do not have individual data from past elections. However, we could assign probabilities utilizing the turnout data of the sub-groups we obtained from exit polls. In our paper we will reflect on both options and compare their performance with regard to an actual forecast. 

<!-- from Lumpley slides
Nonresponse introduces statistical inefficiency
•Nonresponse will also lead to biased estimates if the propensity to respond to the survey(or an item) is related to the attribute of interest
•Ex ante attempts to reduce unit and item nonreponse seldom are fully successful (e.g. increase and dispersion of contact attempts, incentives, conversion by specially trained interviewers, reduction of respondent burden/ interview length via matrix sampling etc.)
•Non response rate and non response bias seem hardly related
•Importance ofex post strategies for missing data
•Different strategies are based on different assumptions about missingness and different kinds of information available on those missing

Poststratification
•Ex poststratification of the sample along one or several categorical variables x…
-… which are suspected to co-determine missingness and the attribute of interest y („commoncauses“ according to Groves, 2006)
-… whose (joint) population distribution is known
•Conceive of the categories/ cross-classifications of x as groups or strata h, use the stratified estimator
•Corrects for disproportionalities between NhN and nh′N that may be either due to sampling or due to non response
•Assumes MAR
--> 