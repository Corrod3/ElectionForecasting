<!-- Introduction -->

<!--The problem -->
The digitalisation is challenging the way polling was done for many decades. Calling people on their landline phones has become difficult as response rates dropped and number of households equipped with landline phones is decreasing [@Skibba.2016]. In response, pollsters have resorted to other polling-methods ranging from face-to-face interviews to mobile phone calling. However, these methods either face similar difficulties to ensure representativeness or are too expensive for regular polling. In order to tackle these obstacles, pollsters are increasingly using online polls, which are cheap and fast, but can be highly non-representative [e.g. @Wang.2015].

<!-- The problem [cont.] -->
The eventual aim of pollsters in online as well as traditional polling is to collect sample data that reflects the view of a population of interest. The major difference between both methods is that for various reasons online polls cannot ensure representativeness before the actual poll takes place. For instance, respondents of online surveys are more likely to be from certain demographic groups or share a particular political background depending on the website or app where the survey is conducted. However, such non-representative polls can be statistically adjusted to match the demographic composition of the population.

Additionally, online election polls, like traditional ones, face another problem. Election forecasters are naturally not only interested in the population as such, but in the population of actual voters. By the time a poll is made representative in demographic terms, it is still in question whether it reflects the group of people who actually cast their ballots. This, however, is crucial in order to make an accurate prediction. Traditional polling tries to account for this using likely voter models and could perform fairly well [@Gallup.2010, @Keeter.2016]. Online surveys will also have to be adjusted to actual voting population in order to provide accurate predictions.

<!-- aim / question / results -->
In this paper, we employed different weighting strategies to an online poll, exploiting respondents usage of smartphone apps. We evaluate our methods against the rolling average of polls from leading German polling institutes. While the raw data of the online survey performed fairly poor compared to our benchmark, we show that with proper weighting we could obtain results that are close to the major polls. Moreover, we compared a rather direct and a indirect method. First, we used information on self-reported vote decision at the German federal election 2013 and data from official exit polls to construct our weights. In a second, more indirect approach, we constructed weights to adjust our demographic clusters to the German census and subsequently identified likely voters. As our results show, the direct method performed considerably better than the indirect weighting through census data.

<!-- Structure  -->
The structure of the paper is as follows: Section two will survey the literature on non-representative polling and presents approaches to employ such data to forecast elections. Subsequently, in chapter three, we present our data and discuss idiosyncratic problems and potential sources of bias. Section four shows the methods we applied to our data. Chapter five is presenting and dicussing our results and their performance against the benchmark. Chapter six concludes and gives an outlook on practical obstacles and methodological issues that our approach suffers from.